{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random, Torch and Cuda settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 50\n",
    "random_seed = 40\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def test(model, dataloader, criterion, device, X_test):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_sobject_ids  = [] \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    predicted_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(dataloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            all_indices = (batch_idx * dataloader.batch_size) + np.arange(target.size(0))\n",
    "            all_sobject_ids.extend(X_test.iloc[all_indices].index.tolist())\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            predicted_probs.extend(F.softmax(output, dim=1).cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc, all_sobject_ids, true_labels, predicted_labels, predicted_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "The .h5 file should contain spectra converted from .fits files as shown in fits_2_h5.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('path-to-dataset.h5')\n",
    "\n",
    "X_train = store['X_train']\n",
    "X_val = store['X_val']\n",
    "X_test = store['X_test']\n",
    "y_train = store['y_train'].values.flatten()\n",
    "y_val = store['y_val'].values.flatten()\n",
    "y_test = store['y_test'].values.flatten()\n",
    "store.close()\n",
    "\n",
    "# Create PyTorch datasets\n",
    "class SpectraDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32).unsqueeze(1)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = SpectraDataset(X_train, y_train)\n",
    "val_dataset = SpectraDataset(X_val, y_val)\n",
    "test_dataset = SpectraDataset(X_test, y_test)\n",
    "\n",
    "# Create PyTorch dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "First we define n_epochs as the uppermost limit before the program termination, patience sets early stopping and run_count defines how many times you want to run the model (with a different random seed each time). \n",
    "The train/val/test_results_{modelname}.csv include probabilites as given by the softmax function. In {modelname}_train-val.csv the loss and accuracy for train and validation sets are saved. In {modelname}_testAcc.csv the accuracy for the test set are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "patience = 5\n",
    "run_count = 5\n",
    "flux_length = 4096\n",
    "\n",
    "run_data = {\n",
    "    'run': [],\n",
    "    'num_epochs': [],\n",
    "    'test_acc': []\n",
    "}\n",
    "\n",
    "test_samples_df = None\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for run in range(run_count):\n",
    "    model = CNN_1a(flux_length)\n",
    "    model = model.to(device)\n",
    "    model_name = model.__class__.__name__[3:] \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Run: ', run, '   Epoch: ', epoch, end='\\r')\n",
    "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc, _, _, _, _  = test(model, val_loader, criterion, device, X_val)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                break\n",
    "\n",
    "    train_loss, train_acc, train_sobject_ids, train_true_labels, train_predicted_labels, train_predicted_probs = test(model, train_loader, criterion, device, X_train)\n",
    "    val_loss, val_acc, val_sobject_ids, val_true_labels, val_predicted_labels, val_predicted_probs = test(model, val_loader, criterion, device, X_val)\n",
    "    test_loss, test_acc, test_sobject_ids, true_labels, predicted_labels, predicted_probs = test(model, test_loader, criterion, device, X_test)\n",
    "\n",
    "    if run == 0: train_samples_df = pd.DataFrame({'sobject_id': train_sobject_ids,'true_label': train_true_labels})\n",
    "    if run == 0: val_samples_df = pd.DataFrame({'sobject_id': val_sobject_ids,'true_label': val_true_labels})\n",
    "    if run == 0: test_samples_df = pd.DataFrame({'sobject_id': test_sobject_ids,'true_label': true_labels})\n",
    "\n",
    "    train_samples_df[f'predicted_label_run_{run + 1}'] = train_predicted_labels\n",
    "    train_samples_df[f'predicted_prob_run_{run + 1}'] = [max(probs) for probs in train_predicted_probs]\n",
    "\n",
    "    val_samples_df[f'predicted_label_run_{run + 1}'] = val_predicted_labels\n",
    "    val_samples_df[f'predicted_prob_run_{run + 1}'] = [max(probs) for probs in val_predicted_probs]\n",
    "\n",
    "    test_samples_df[f'predicted_label_run_{run + 1}'] = predicted_labels\n",
    "    test_samples_df[f'predicted_prob_run_{run + 1}'] = [max(probs) for probs in predicted_probs]\n",
    "\n",
    "    run_data['run'].append(run + 1)\n",
    "    run_data['num_epochs'].append(epoch + 1)  # epoch is zero-indexed, so adding 1\n",
    "    run_data['test_acc'].append(test_acc)\n",
    "\n",
    "    data = {\n",
    "        'run': [run + 1] * len(train_losses),\n",
    "        'epoch': list(range(1, len(train_losses) + 1)),\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "    torch.save(model.state_dict(), f'models_saved/{modelname}_run_{run + 1}.pth')\n",
    "\n",
    "df_run = pd.DataFrame(run_data)\n",
    "\n",
    "\n",
    "train_samples_df.to_csv(f\"train_results_{modelname}.csv\", index=False) \n",
    "val_samples_df.to_csv(f\"val_results_{modelname}.csv\", index=False)\n",
    "test_samples_df.to_csv(f\"test_results_{modelname}.csv\", index=False)\n",
    "all_data.to_csv(f'{modelname}_train-val.csv', index=False)\n",
    "df_run.to_csv(f'{modelname}_testAcc.csv', index=False)\n",
    "\n",
    "print('FINISHED!')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
